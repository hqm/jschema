
sbt
run

There are two world Planes - front and back

+ world needs background spatial markers for navigation


What is the API to the sensorimotor system? 

Models:
  blocks with friction, density, texture

   server can implementat 'sticky' blocks



Motor output:

System has two arms. Each has two joints and a hand:

  Gross motor action: upper arm, moves to a quadrant of screen, say 1/10 quantized

  Fine motor action: lower arm, moves 1/10 of quadrant

  Rotator Joints at the shoulder and elbow, i.e., there is redundancy for reaching a point but that
  allows for better reuse of relative motion schemas

  Gross and fine joints have control over force left,right, up/down

  "Lift" pulls a block out of the plane so it can be moved over other blocks.

  - The motor system provides both force and a targeted 'move to proprioceptive position' function. E.g., 
  we've got a fairly high level motor system.

  hand: grasp, ungrasp, rotate left, rotate right
    grasp and rotate force is controllable over some range
     -- the 'grasp' operation gives a force feedback of "grip" when there is an object touching, with force sensation
        proportional to the gripping force, like when you squeeze a block with you fingers.


    HEAD: rotatation , translation

    Gaze: 10x10 gross angle quantization
    	  10x10 fine angle position

Also see Vision system, there is 'motor control' of internal pipeline vision filters, you can
choose which ones go into pipeline

Vocal: phoneme output

Sensor inputs:

  Proprioception: 
     10x10 location for gross motor system - divided into x,y axis? 
     10x10 location for fine motor system 
     shoulder and elbow joint position

Force/touch

     force on shoulder joint, x, y, rotation

     force on elbox x,y,rotation

     force on wrist join rotation, x, y 

     force on grasp

     touch on fingers, texture, temperature, heat conductivity, on fingers. 

     

Vision

  modules:

  broad-area vision - blob detection per quadrant, a couple of bits of color/grayscale

  fovea operations:

     closed area fill - is area at fovea closed? 
     are there any bits on at the fovea ; color, density, texture (image morphology bank of filters)

  filter system (image morphology)
    prescale
    erode/dilate
        

   motion tracking; attention focus points on fovea and broad-area peripheral vision  when motion is sensed

   trajectory - when motion detected, a motion vector input is stimulated

Audio

  Basic frequency burst (pop, click, boom), localization from auditory system to a quadrant
  Phoneme inputs



================================================================

How is sensorimotor info passed to schema engine? 

class SensoryInput {
      int id; // a unique id for this input
      boolean value;
      boolean changed;
}

class MotorAction {
      int id; // unique id for this output
      boolean value;
}

class WorldState {

      ArrayList<SensoryInput> inputList = new ArrayList<SensoryInput>();

      ArrayList<MotorAction> outputList = new ArrayList<MotorAction>();

}




================
Questions:

How do infants learn to keep still? I.e., it's important to only be moving a few things at time, initially.
So you need to keep most of the body still. And for fine motor activity need to keep the gross motor joints still.

How much of that is built in? You need to set the opposing muscles at
exactly the same force to maintain constant proprioceptive input. In
terms of schema, what are the interesting schemas being learned there,
to maintain that invariant input? Why is it interesting to the Schema mechanism to learn
to keep limbs still by default?  Or to keep head aligned with an object to keep it centered in fovea? 




 


call Hal Abelson


export CLASSPATH=lib/controlP5.jar:lib/core.jar:lib/gluegen-rt.jar:lib/jbox2d_2.1.2_ds_v2.jar:lib/jogl-all.jar:lib/jruby-complete-1.7.4.jar:lib/pbox2d.jar:lib/slf4j-api-1.6.4.jar:lib/slf4j-nop-1.6.4.jar:lib/trove4j-3.0.3.jar:lib/typesafe-config.jar:target/scala-2.10/jschema_2.10-1.1.jar 

jirb 
load 'doit'




